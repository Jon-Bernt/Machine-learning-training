{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "First machine learning project with tensorflow on mnist dataset",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jon-Bernt/Machine-learning-training/blob/master/First_machine_learning_project_with_tensorflow_on_mnist_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCDw95ZAXUwX",
        "colab_type": "code",
        "outputId": "986ab8eb-a642-43a2-cbda-4948d9c34c7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import ops\n",
        "from keras.models import Sequential\n",
        "tf.compat.v1.one_hot\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "# Read data\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "np.random.seed()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkfGF7XWjkmY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6g8Qsn88qsyN",
        "colab_type": "code",
        "outputId": "6fdd4641-e294-4887-928f-bcdec8f60a1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "#example of a picture with corresponding lable\n",
        "index = 0\n",
        "plt.imshow(x_train[index])\n",
        "print (\"y = \" + str(y_train[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y = 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSRB2IAnCDiTx/65XcTNOWsh5AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9Z-x3lvsGKS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Flatten the training and test images\n",
        "X_train_flatten = x_train.reshape(x_train.shape[0], -1).T\n",
        "X_test_flatten = x_test.reshape(x_test.shape[0], -1).T\n",
        "# Normalize image vectors\n",
        "X_train = X_train_flatten/255.\n",
        "X_test = X_test_flatten/255.\n",
        "# Convert training and test labels to one hot matrices\n",
        "Y_train = tf.one_hot(y_train, 10)\n",
        "Y_test = tf.one_hot(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4aDt0DH6zxm",
        "colab_type": "text"
      },
      "source": [
        "The mnist training dataset contains 60 000 handwritten images from 0-9, test set contains 10 000 images, 28 x 28 pixels\n",
        "[Mnist dataset info](http://yann.lecun.com/exdb/mnist/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e08I7J52xmjD",
        "colab_type": "code",
        "outputId": "cfb0a5c4-6133-4eb5-be51-5a745094b375",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print (\"number of training examples = \" + str(X_train.shape[1]))\n",
        "print (\"number of test examples = \" + str(X_test.shape[1]))\n",
        "print (\"X_train shape: \" + str(X_train.shape))\n",
        "print (\"Y_train shape: \" + str(Y_train.shape))\n",
        "print (\"X_test shape: \" + str(X_test.shape))\n",
        "print (\"Y_test shape: \" + str(Y_test.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of training examples = 60000\n",
            "number of test examples = 10000\n",
            "X_train shape: (784, 60000)\n",
            "Y_train shape: (60000, 10)\n",
            "X_test shape: (784, 10000)\n",
            "Y_test shape: (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-9amgOq7g6Z",
        "colab_type": "text"
      },
      "source": [
        "#Creating placeholders for X and Y. Allows for training data to be passed in when running the session.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gj_x8Rv433_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_placeholders(n_x, n_y):\n",
        "    \"\"\"\n",
        "    To create placeholders (similar to variables) for the tensorflow session I need to define two arguments which are 1.size of image and 2. number of classes.\n",
        "    \n",
        "    Arguments:\n",
        "    n_x -- scalar, size of an image vector (num_px * num_px = 28 * 28 = 784)\n",
        "    n_y -- scalar, number of classes (from 0 to 9, so -> 10)\n",
        "    \"\"\"\n",
        "    X = tf.placeholder(tf.float32, shape = [n_x, None], name = \"X\")\n",
        "    Y = tf.placeholder(tf.float32, shape = [n_y, None], name = \"Y\")\n",
        "    \n",
        "    #using \"None\" so that I can be flexible on the number of examples (different for training and test dataset) \n",
        "    \n",
        "    return X, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKcw5rSE5aeX",
        "colab_type": "code",
        "outputId": "e35704d0-d06e-49bc-a6f8-43e92dc4b1e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "X, Y = create_placeholders(784, 10)\n",
        "print (\"X = \" + str(X))\n",
        "print (\"Y = \" + str(Y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X = Tensor(\"X_1:0\", shape=(784, ?), dtype=float32)\n",
            "Y = Tensor(\"Y_1:0\", shape=(10, ?), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rTWLH776V_8",
        "colab_type": "text"
      },
      "source": [
        "#Initializing parameters for the model\n",
        "Use Xavier Initialization for weights and Zero Initialization for biases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLJKV5ub5lCZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_parameters():\n",
        "  \"\"\"\n",
        "  Initializes parameters to build a neural network with tensorflow. The shapes are:\n",
        "                        W1 : [25, 784]\n",
        "                        b1 : [25, 1]\n",
        "                        W2 : [12, 25]\n",
        "                        b2 : [12, 1]\n",
        "                        W3 : [10, 12]\n",
        "                        b3 : [10, 1]\n",
        "  Returns:\n",
        "  parameters -- a dictionary of tensors containing W1, b1, W2, b2, W3, b3\n",
        "  \"\"\"\n",
        "  tf.set_random_seed(1)\n",
        "\n",
        "  W1 = tf.get_variable(\"W1\", [25,784], initializer=tf.contrib.layers.xavier_initializer(seed = 1))\n",
        "  b1 = tf.get_variable(\"b1\", [25,1], initializer=tf.zeros_initializer())\n",
        "  W2 = tf.get_variable(\"W2\", [12,25], initializer=tf.contrib.layers.xavier_initializer(seed = 1))\n",
        "  b2 = tf.get_variable(\"b2\", [12,1], initializer=tf.zeros_initializer())\n",
        "  W3 = tf.get_variable(\"W3\", [10,12], initializer=tf.contrib.layers.xavier_initializer(seed = 1))\n",
        "  b3 = tf.get_variable(\"b3\", [10,1], initializer=tf.zeros_initializer())\n",
        "\n",
        "  #Dictionary:\n",
        "  parameters = {\"W1\": W1,\n",
        "                \"b1\": b1,\n",
        "                \"W2\": W2,\n",
        "                \"b2\": b2,\n",
        "                \"W3\": W3,\n",
        "                \"b3\": b3}\n",
        "\n",
        "  return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6gpiQah9lGJ",
        "colab_type": "code",
        "outputId": "db8a172b-94dd-4f5a-d451-20ee42f40c5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "tf.reset_default_graph()\n",
        "with tf.Session() as sess:\n",
        "    parameters = initialize_parameters()\n",
        "    print(\"W1 = \" + str(parameters[\"W1\"]))\n",
        "    print(\"b1 = \" + str(parameters[\"b1\"]))\n",
        "    print(\"W2 = \" + str(parameters[\"W2\"]))\n",
        "    print(\"b2 = \" + str(parameters[\"b2\"]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W1 = <tf.Variable 'W1:0' shape=(25, 784) dtype=float32_ref>\n",
            "b1 = <tf.Variable 'b1:0' shape=(25, 1) dtype=float32_ref>\n",
            "W2 = <tf.Variable 'W2:0' shape=(12, 25) dtype=float32_ref>\n",
            "b2 = <tf.Variable 'b2:0' shape=(12, 1) dtype=float32_ref>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iljiyf-t-krn",
        "colab_type": "text"
      },
      "source": [
        "#Forward propogation in tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VmsNjIX-pTs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_propagation(X, parameters):\n",
        "    \"\"\"\n",
        "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
        "    parameters -- python dictionary containing parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
        "                  the shapes are given in initialize_parameters\n",
        "\n",
        "    Returns:\n",
        "    Z3 -- the output of the last LINEAR unit\n",
        "    \"\"\"\n",
        "    \n",
        "    # Retrieve the parameters from the dictionary \"parameters\" \n",
        "    W1 = parameters['W1']\n",
        "    b1 = parameters['b1']\n",
        "    W2 = parameters['W2']\n",
        "    b2 = parameters['b2']\n",
        "    W3 = parameters['W3']\n",
        "    b3 = parameters['b3']\n",
        "    \n",
        "                                                                     # Numpy Equivalents:\n",
        "    Z1 = tf.add(tf.matmul(W1, X),b1)                                 # Z1 = np.dot(W1, X) + b1\n",
        "    A1 = tf.nn.relu(Z1)                                              # A1 = relu(Z1)\n",
        "    Z2 = tf.add(tf.matmul(W2, A1),b2)                                # Z2 = np.dot(W2, A1) + b2\n",
        "    A2 = tf.nn.relu(Z2)                                              # A2 = relu(Z2)\n",
        "    Z3 = tf.add(tf.matmul(W3,A2),b3)                                 # Z3 = np.dot(W3, A2) + b3\n",
        "\n",
        "    \n",
        "    return Z3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pONyyrC8_jKP",
        "colab_type": "code",
        "outputId": "a31b3ca5-24ca-4b3e-fa94-bf936f47bd75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    X, Y = create_placeholders(784, 10)\n",
        "    parameters = initialize_parameters()\n",
        "    Z3 = forward_propagation(X, parameters)\n",
        "    print(\"Z3 = \" + str(Z3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Z3 = Tensor(\"Add_2:0\", shape=(10, ?), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "190SeC76_6b3",
        "colab_type": "text"
      },
      "source": [
        "#Computing the cost function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBKUbk2IA_ER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_cost(Z3, Y):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "  Z3 -- output of forward propagation (output of the last LINEAR unit (z)), of shape (10, number of examples)\n",
        "  Y -- \"true\" labels vector placeholder, same shape as Z3\n",
        "\n",
        "  Cost function:\n",
        "  tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = ..., labels = ...))\n",
        "\n",
        "  tf.reduce_mean() means that we are summing over the examples.\n",
        "\n",
        "  The cost function in tensorflow requires arguments \"logits\" and \"labels\" that are of same shape as the original dataset (number_of_examples, number_of_classes).\n",
        "  Logits is the output of the last linear function Z with shape (10, number_of_examples). Labels has the same shape (10, number_of_examples).\n",
        "  I therefore need to transpose these two variables to fit the tensorflow requirement.  \n",
        "\n",
        "  Returns:\n",
        "  cost - Tensor of the cost function\n",
        "  \"\"\"\n",
        "  logits = tf.transpose(Z3)\n",
        "  labels = tf.transpose(Y)\n",
        "\n",
        "  cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))\n",
        "\n",
        "  return cost\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHOJ6RMQDjfs",
        "colab_type": "code",
        "outputId": "c04ab06b-94a9-4244-9809-336969edfe3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    X, Y = create_placeholders(784, 10)\n",
        "    parameters = initialize_parameters()\n",
        "    Z3 = forward_propagation(X, parameters)\n",
        "    cost = compute_cost(Z3, Y)\n",
        "    print(\"cost = \" + str(cost))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cost = Tensor(\"Mean:0\", shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMtVLLNyFF5K",
        "colab_type": "text"
      },
      "source": [
        "#Creating model to bring all functions together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83SIMVImFKNu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n",
        "          num_epochs = 1500, batch_size = 32, print_cost = True):\n",
        "  \n",
        "\n",
        "  ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
        "  tf.set_random_seed(1)                             # to keep consistent results\n",
        "  seed = 3                                          # to keep consistent results\n",
        "  (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
        "  n_y = Y_train.shape[0]                            # n_y : output size\n",
        "  costs = []                                        # To keep track of the cost\n",
        "\n",
        "  # Create Placeholders of shape (n_x, n_y)\n",
        "  X, Y = create_placeholders(n_x, n_y)\n",
        "\n",
        "  # Initialize parameters\n",
        "  parameters = initialize_parameters()\n",
        "  \n",
        "  # Forward propagation: Build the forward propagation in the tensorflow graph\n",
        "  Z3 = forward_propagation(X, parameters)\n",
        "  \n",
        "  # Cost function: Add cost function to tensorflow graph\n",
        "  cost = compute_cost(Z3, Y)\n",
        "  \n",
        "  # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
        "  optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
        "  \n",
        "  # Initialize all the variables\n",
        "  init = tf.global_variables_initializer()\n",
        "\n",
        " \n",
        "\n",
        "  # Start the session to compute the tensorflow graph\n",
        "  with tf.Session() as sess:\n",
        "      \n",
        "      # Run the initialization\n",
        "      sess.run(init)\n",
        "      \n",
        "      # Do the training loop\n",
        "      for epoch in range(num_epochs):\n",
        "          epoch_cost = 0.                       # Defines a cost related to an epoch\n",
        "          \n",
        "          for _ in range(int(mnist.train.num_examples/batch_size)):\n",
        "            epoch_x, epoch_y = mnist.train.next_batch(batch_size)\n",
        "            _ , c = sess.run([optimizer, cost], feed_dict={X:epoch_x, Y:epoch_y})\n",
        "            epoch_cost += c\n",
        "\n",
        "          # Print the cost every epoch\n",
        "          # if print_cost == True and epoch % 100 == 0:\n",
        "          #     print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
        "          # if print_cost == True and epoch % 5 == 0:\n",
        "          #     costs.append(epoch_cost)\n",
        "\n",
        "          print (\"Epoch\", epoch, \"completed out of\", num_epochs, \"loss:\", epoch_cost)\n",
        "\n",
        "      # plot the cost\n",
        "      plt.plot(np.squeeze(costs))\n",
        "      plt.ylabel('cost')\n",
        "      plt.xlabel('iterations (per fives)')\n",
        "      plt.title(\"Learning rate =\" + str(learning_rate))\n",
        "      plt.show()\n",
        "\n",
        "      # lets save the parameters in a variable\n",
        "      parameters = sess.run(parameters)\n",
        "      print (\"Parameters have been trained!\")\n",
        "\n",
        "      # Calculate the correct predictions\n",
        "      correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
        "\n",
        "      # Calculate accuracy on the test set\n",
        "      accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "\n",
        "      print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
        "      print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
        "      \n",
        "      return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9FMDMSWF_kv",
        "colab_type": "code",
        "outputId": "35399748-7e2d-4434-970c-859080015a69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "parameters = model(X_train, Y_train, X_test, Y_test)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-aa22b73f05b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-67-ebca3d439e42>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(X_train, Y_train, X_test, Y_test, learning_rate, num_epochs, batch_size, print_cost)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m60000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mepoch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0m_\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mepoch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mepoch_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mepoch_cost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1154\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m                 (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1157\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (32, 10) for Tensor 'Reshape_1:0', which has shape '(60000, 1)'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oROoU74DG1q7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}